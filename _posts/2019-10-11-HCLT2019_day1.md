---
layout: post
title: 제31회 한글 및 한국어 정보 처리 학술대회 1일차
category: conference
tags: [HCLT]

---

<h3>송현제 교수/ 전북대</h3>
<h3>한국어 형태소 분석기의 기계학습 접근방식</h3>
<ul>
<li><p>1980년대 이후부터 룰 기반 방법이 연구되어왔음.</p>
</li>
<li><p>기계학습 기반방식에 대해 소개. 한국어 형태소 분석기는 형태소와 형태소에 해당하는 품사는 output으로</p>
</li>
<li><p>중국어는 한국어와 유사하나 한국어만의 차이가 있다</p>
</li>
<li><p>크게 3가지 방식 
1)복합태그 라벨링 -&gt; post 프로세싱</p>
<p>나는 하늘을 나는 새를 봤다.
khaiii 의 방식</p>
<p>속도가 빠르고 robust, linguistic resources, 파이프라인 를 사용한다</p>
<p>2)morphenme 프로세싱 -&gt; pos 태깅</p>
<p>사전없이 형태소 분석을 할 수 있는방법은?</p>
<p>파이프라인</p>
<p>3)형태소 분석을 번역의 문제로 해석</p>
<p>시퀀스를 나열해서 end2end로 학습이 가능하다
형태소 분석은 어순의 변화가 없어서 attn 필요없다. 컨볼루션 피쳐를 통해 해결</p>
<p>액션 베이스</p>
</li>
<li><p>형태소 분석기를 multi task로 풀어보자
morpheme processing, pos tagging 두개의 task를 join하는 걸로 진행
디코더를 한개만 사용해서 2개의 task를 해결. 하나의 형태소에 대해 하나의 품사로 대응
<a href='https://github.com/songhyunje/kma' target='_blank' class='url'>https://github.com/songhyunje/kma</a></p>
</li>
<li><p>기존 multi task 방식은
입력을 공유하되 2개의 아웃풋이거나 첫번째 아웃풋이 두번째 입력값으로 가거나
triangle 방식 </p>
</li>
<li><p>Latex format 많이 써달라.</p>
</li>
<li><p>세종데이터셋 기반으로만 만들어졌다. 더 많은 데이터셋으로 만들어보라</p>
<p>&nbsp;</p>
</li>

</ul>
<h3>이연수 / NCSOFT NLP Lab</h3>
<h3>NLP@NC</h3>
<ul>
<li><p>nc ai day 행사가 있다 올해 3번째</p>
</li>
<li><p>데이터의 시대, 러닝</p>
</li>
<li><p>지식 AI랩, AI 서비스실 -&gt; NLP센터 소속</p>
</li>
<li><p>게임 적용 AI
모션 스타일 트랜스퍼/ 학습 기반 IK / text 2 animation / 캐릭터얼굴 아이콘 생성</p>
</li>
<li><p>사람들이 사용하는 언어로 소통하는 기술</p>
<p>데이터를 요약 연결 구조화 적절한 표현과 관련지식을 추론</p>
<p>데이터의 콘텐츠화</p>
<p>발견/ 추상화/ 추론</p>
</li>
<li><p>ai가 만드는 재미있는 야구 이야기 -PAIGE</p>
</li>
<li><p><strong>text style transfer</strong> 문체변환
구어체로 바꾸는 기술 기사문어체 -&gt; 예의바른 구어체
가이드 라인에 따른 병렬 코퍼스 생성
Unsupervised 로도 성능은 나온다</p>
</li>
<li><p>NLG , 생성기술</p>
</li>
<li><p>AI로 전해주는 야구 중계체 합성, </p>
</li>
<li><p>야구라는 도메인을 선택한 이유 정량적, 정성적 데이터가 많음</p>
</li>
<li><p>nlp platform 을 구축해서 </p>
</li>

</ul>
<p>&nbsp;</p>
<h3>김주호 교수 / kaist</h3>
<h3>Conversational Interaction Design</h3>
<ul>
<li><p>nlp는 잘 모르지만 HCI 연구중</p>
</li>
<li><p>인간과 컴퓨터가 상호작용하는  사람 - 다대 컴퓨터 , 다대 사람 - 컴퓨터</p>
</li>
<li><p>대화가 상호작용의 중요한 unit</p>
</li>
<li><p>GUI의 벽을 넘기위한 대안은 대화형 챗봇 같은</p>
</li>
<li><p>part1 솔루션챗 , 슬랙대화를 통해 대화에서 끝나지않고 대화가 시위나 집회와 같은 활동으로 이어짐
사람 진행자를 대체하는 AI 진행자를 만들어보자, 조금만 어긋나도 사람들의 신뢰도는 급감</p>
<p>Chat only  + agenda panel + message recommendations 옵션을 추가해서 비교</p>
<p>더 좋은 토론을 만드는걸 돕는다</p>
</li>
<li><p>part2 챗봇 디자인 
챗봇은 정형화된 답을 내는데, 개인화된 조금 다른 답을 내게 할 수는 없을까?
사람과 agent의 관계를 나타내지않는다. 보통은 비서 persona, 생각해본다면 선생님 같은 persona, 다중적인 persona도 가능하지 않을까
의도와 context 를 이해하지 않는다
시간의 변화에 따라 변하지 않는다. 오랜시간 사용했음에도</p>
</li>
<li><p>verbal response modes
사람들이 말할 때 관계, 관점에 따라 달라진다...</p>
<ul>
<li><p>(내가, 상대방)이 알고있는 것에 대해 (내, 상대방)의 관점에서 (나만의,상대방)의 경험이나 관점에 기반을 해서 이야기하는 것.</p>
<p>8가지 타입이 나온다</p>
<p>상호확인 :
질문 : 
확인 : 
반복, 투영</p>
</li>

</ul>
</li>
<li><p>vrm을 통한 사용자 맞춤형 대화 인터랙션 설계
사용자의 단기적 의도 파악에 장점을 가짐
대화를 보고 어떤 vrm 모드인지를 분류하는 모델
다소 주관적이고 라벨링 난이도가 높다. 모델 측면에서는 단순해서 장점, 데이터 측면에서는 단점.</p>
</li>
<li><p>이걸로 뭐할건지?
의사가 환자에게 객관적인 정보를 더 유도할수있음
부모-자녀 상호작용
한국어 기반 VRM classifier 개발</p>
<ul>
<li>기존 영어 화행 기반 vrm 데이터를 한국어로 번역한 후 모델 개발</li>

</ul>
<p>데이터 셋 및 classifier 공개예정</p>
</li>
<li><p>스스로 한국어 학습을 하는 외국인 학습자를 위한 언어 학습용 챗봇</p>
</li>
<li><p>어린이의 스토리 읽기 경험을 도와주는 영상 + 챗봇 연계 시스템
영상과 챗봇이 연계되어있는, 삼성전자 빅스비 팀과 같이 진행</p>
</li>
<li><p>챗봇의 인터랙티브한 설계 과정을 돕는 툴
ide 툴처럼 대화의 큰 뼈대를 설계한 다음 다시 추가하는 </p>
</li>
<li><p>대화는 중요. 인간처럼 말하는 것에 초점을 맞추기보다
새로운 인터랙티브 시스템의 블록단위가 될것</p>
</li>

</ul>
<p>&nbsp;</p>
<h3>임해창 교수 / NCSOFT</h3>
<h3>자연어처리의 진화</h3>
<p><a href='http://www.kunews.ac.kr/news/articleView.html?idxno=24735' target='_blank' class='url'>http://www.kunews.ac.kr/news/articleView.html?idxno=24735</a></p>
<ul>
<li><p>초기의 자연어처리 시스템
최초의 AI시스템 (ELIZA) : 패턴매칭과 대체방법을 이용하여 적절하게 대화를 흉내
turing system : 인공지능의 척도 
SHRDLU : 최초의 자연어 이해 시스템
conceptual dependency theory (의미표현) : 인간이 사용하는 
augmented Transition net (구문파서)
baseball and lunar (QA 시스템)
db 자연어 인터페이스 : 질문을 파싱하기 위하여 의미문법을 사용.
통계적 자연어 처리::: nlp의 혁명 룰기반에서의 변화</p>
<p>품사태깅 모델의 확률적 정의 : HMM은 품사태깅을 위한 가장 인기있는 모델, 형태소 품사들의 모든 가능한 경로 중에서 확률이 가장높은 경로를 찾는다</p>
<p>단어 의미 중의성 해결</p>
<p>SVM :
CRFs : 구조화된 예측에 기반한 기계학습모델</p>
</li>
<li><p>오늘의 자연어처리
nlp를 위한 딥러닝의 발전, 문맥의 표현, 학습의 재활용</p>
<p>기존의 기계학습 방법들은 인간이 설계한 표현과 입력자질 그리고 가중치 최적화를 통하여 예측</p>
<p>딥러닝은 자동으로 좋은 자질들과 표현들을 학습하도록 시도
단어표현/seq2seq/attn/
단어표현 : 
CNN은 순서에 상관없이 단어들이나 N-gram
RNN은 시퀀스 정보를 효율적으로 처리하는데</p>
<p>attn
메모리 기반 모델 : 언어모델이나, QA와 같은 더 긴 
GAN : 적대적 예제들은 모델을 검증하고 실패한 경우를 이해하고 또한 모델을 더욱 강건하게 만들기 위한 도구, 언어생성이나 대화 또는 기계번역에 적용가능
강화학습 : 학습 중에 실시간으로 데이터를 선택하거나 대화를 모델링하는 것이나 동시통역과 같은 시간 의존관계를 가진 태스크에 강화학습이 유용하다고 증명됨.
문맥의 표현
	모든 문맥을 , ELMo는 양방향 두 언어모델을 결합하여 전체 문맥 저보가 반영된 임베딩을 구축
	GPT : 인코더 파트를 무시하고 트랜스포머 디코더 모델을 활용하여 단일 문장을
	BERT : 언어 이해를 위한 심층 양방향 트랜스포머의 사전 학습
	XLNet : seq에 대한 permutation 조합을 만든 뒤 언어 모델링을 진행하는 permutation lm 방식채택</p>
<p>학습의재활용</p>
<p>	전이학습이란 소스 태스크들로부터 학습된 지식이 전이되어 관련된 타겟 태스크의 학습을 개선하는데 사용되는 접근방법
​	전이 학습의 대부분의 방법들은 언어 모델에 기반
​	문맥을 반영한 벡터를 반영후 학습시켜야.
​	언어 모델 사전학습의 장점
​		다양한 학습 방법이 가능
​		정답 부착 데이터가 필요없음
​	언어모델 사전학습 기반 모델의 뛰어난 성능 7개 태스크.</p>
<p>인간 지도의 최소화</p>
<p>	데이터 효율을 최대화하면 매우 적은 지도학습 데이터로 모델 훈련이 가능해짐
​	인간에게는 자연스럽지만, 기계에게는 매우 
​	병렬 코퍼스가 없는 기계번역</p>
<p>지식과 딥러닝의 통합</p>
<p>	단어 간의 관계를 정의한 지식들을 활용
​	텍스트 정보를 언어적 관계 정보가 정의된 지식을 활용하여 표상
​	감정 분석을 수행하기 위하여 </p>
<p>멀티모달, 다국어, 분야의 세분화</p>
<p>	비전과 자연어처리::
​	텍스트에서 얼굴을 생성하기 위한 모델 학습 -&gt; 몽타주
​	레시피 QA : 텍스트와 이미지를 같이 이해해야 가능함.
​	감정분석 : 풍자탐지, 다국어 감정분석.</p>
<p>	text2text 요약, 제목생성,
​	건강을 위한 자연어처리 : 이질적인 자원을 합쳐서 정확한 정보를 획득하는데 NLP를 사용
​	임상 의사 결정에 도움이 되는 빠르고 효율적인 제안을 하는데 nlp가 사용
​	대화하는 인공지능 : 
​	squad :: 질의응답
​	VIST : visual story telling challenge</p>
<p>공공성 및 도덕성 강조::</p>
<p>	공개된 언어자원의 증가
​	성 차별의 감소/ 환자들을 위한 안전에 대한 관심
​	새로운 자연어 추론 데이터 집합 SWAG
​	도덕적인 기계학습</p>
</li>
<li><p>미래의 자연어처리</p>
<p>NLP는 AI를 보다 인간처럼 만들 수 있는 핵심 기술이 될 것
평가 : 인간의 평가와 일치하는 새로운 평가척도</p>
<p>정보추출 : 정보를 추출하여 지능을 수집</p>
<p>정보검색 : 키워드 기반 검색엔진 소멸, 이야기하듯이 검색이 가능</p>
<p>건강관리 시스템의 보조</p>
<ul>
<li>우리가 개발한 모델과 도구들이 많은 실제적인 문제를 다룰 수 있는 위치에 도달할 것</li>
<li>자연어처리의 미래는 문자 그대로 제한이 없을것</li>
<li>자연어처리가 인공지능 기술의 핵심이 될것</li>
<li>인공지능 시스템을 보다 인간처럼 만드는 NLP</li>

</ul>
<p>과거의 지식들은 단순히 과거의 지식이 아니다 배경지식을 삼으면 딥러닝을 하는데 자산이 될듯</p>
</li>

</ul>
