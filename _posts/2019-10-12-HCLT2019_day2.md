---
layout: post
title: 제31회 한글 및 한국어 정보 처리 학술대회 2일차
category: conference
tags: [HCLT]
---

한글 및 한국어 정보 처리 학술대회 2일차에 참여하여 보고 들은 내용을 정리해보고자 합니다


<br><br><br>

<h2>2일차 구두발표</h2>
<h3>베이지안 모델 불확실성에 기반한 오픈도메인 질의응답</h3>
<ul>
<li><p>도메인측면에서 보면</p>
<ul>
<li>한정된 도메인</li>
<li>특정 도메인에 종속X , 포괄적인 질문-정답유형, 추가적인 IRQA</li>

</ul>
</li>
<li><p>IRQA</p>
<ul>
<li>문서 정답이 존재하지 않는 경우 치명적</li>
<li>NIL : 문서에 정답이 존재하는 케이스</li>

</ul>
</li>
<li><p>불확실성</p>
<ul>
<li>딥러닝 모델이 예측한 결과가 정상적으로 예측된 결과인지, 오버피팅으로 인한 결과인지</li>

</ul>
</li>
<li><p>베이지안 딥러닝</p>
<ul>
<li>변분추론</li>
<li>몬테-카를로 드랍아웃</li>

</ul>
</li>
<li><p>강화학습을 이용하여 선택한 문서에 정답이 존재할 경우 </p>
</li>
<li><p>ranker : 정답이 포함되어있을 가능성이 가장 높은 문서선택</p>
</li>
<li><p>reader : 문서에서의 정답의 시작과 끝의 확률계산을 통해 정답추출</p>
</li>
<li><p>최종 결과의 컨피던스 계산 시, 동일한 예측 결과지만 span 다른 경우 word overraping 을 이용하여 해결</p>
</li>
<li><p>EM과 F1 스코어 가 비슷하다는건 단답형 대답이 많다는 건지? 질문유형에 대한 분석이 되었는지?</p>
</li>

</ul>
<p>&nbsp;</p>
<h3>KorQuAD 2.0: 웹문서 기계독해를 위한 한국어 질의응답 데이터셋 / 김영민</h3>
<ul>
<li><p>기존에는 1-2개 문단에서, 2.0 위키문서 전체에서 탐색</p>
</li>
<li><p>표와 같이 구조화된 문서도 포함, 표는 2차원적인</p>
</li>
<li><p>문단과 같이 긴답변도 가능한지, 문단이 답변인게???</p>
</li>
<li><p>데이터 수집 과정</p>
<ul>
<li><p>질문 -답변 생성
크라우드 소싱. 사전 과제 테스트를 통과한 사라만 과제작업자로 참여가능</p>
<p>text vs table, long vs short, </p>
</li>
<li><p>1.0데이터 전체를 변환</p>
</li>
<li><p>모드</p>
</li>

</ul>
</li>
<li><p>데이터 분석</p>
<ul>
<li>전체 103,193 개의 qa쌍, 평균 2.15개의 q-a쌍으로 다양한 주제의 문서들 포함</li>
<li>bert 는 512개토큰 이 최대인데 
답변길이는 최대 만자도 있다 참고,</li>

</ul>
</li>
<li><p>성능평가방식</p>
<ul>
<li><p>EM, F1, Latency: 데이터 전처리, 모델 추론을 포함한 질문 하나당 평균소요 시간</p>
</li>
<li><p>baseline 모델인 구글 bert multi 을 활용하여 확인해본결과</p>
<ul>
<li>30.2 / 46 (EM/F1)</li>
<li>문서가 길고 복잡할수록, 표나 리스트의 경우 더 어려움</li>

</ul>
</li>

</ul>
</li>
<li><p>baseline 분석</p>
<ul>
<li>중복 비율 감소에 따라 사람에 비해 기계독해의 성능감소가 크다 , 일반화된 모델이 필요하다</li>

</ul>
</li>
<li><p>결론</p>
<ul>
<li>현실에서 필요로 하는 과제 해결을 위한 모든것!</li>

</ul>
</li>
<li><p>질문</p>
<ul>
<li>단락을 제공하고 질문을 생성하는 것과 그냥 주제만 주고 질문을 생성하는 것 차이가 있지않나?</li>

</ul>
</li>

</ul>
<p>&nbsp;</p>
<h3>한국어 질의 응답에서의 화제성을 고려한 딥러닝 기반 정답 유형 분류기</h3>
<ul>
<li><p>정답 유형 분류란?</p>
<p>주어진 질의 문장에 대한 예상 정답 유형을 예측</p>
</li>
<li><p>문맥 보완 필요성</p>
<ul>
<li>주제어의 변화에 따른 분류 차이를 주위 문맥을 알기 어려움</li>
<li>새롭게 등장하는 개체명에 대해서도 지속적인 관리가 필요</li>

</ul>
</li>
<li><p>주어 및 속성 표현 추출</p>
<ul>
<li>주제어 후보의 쿼리 카운트가 월 1000회 이상 검색되었을 때 저장 (3300여개)</li>
<li>속성 표현은 주제어가 달라져도 정보를 일관적으로</li>

</ul>
</li>
<li><p>방법론</p>
<ul>
<li><p>신경망 분류 모델</p>
<ul>
<li>실서비스를 위한 속도를 만족하기 위하여 합성곱 신경망을 선택</li>
<li>깊이별 합성곱 신경망 으로 문맥을 파악해서 분류</li>

</ul>
</li>

</ul>
</li>
<li><p>결론 </p>
<ul>
<li>검색 쿼리를 통하여 주제어의 화제성을 반영</li>
<li>주제어와 속성 표현을 명시적으로 모델에 전달하여 분류 성능 개선</li>
<li>위키피디아 인포박스는 속성표현으로 활용이 가능하다...</li>

</ul>
</li>

</ul>
<p>&nbsp;</p>
<h3>기계 독해를 이용한 웹 기반 오픈 도메인 한국어 질의응답</h3>
<ul>
<li><p>최종목표 : 무작위 질문에 대하여 답변하기</p>
</li>
<li><p>마우스 언제 만들어졌어? 라는 질문에 대한 검색결과는...</p>
</li>
<li><p>검색결과의 신뢰성 
-&gt; 최대한 많은 문서를 분석한 후, 결과값을 조합을 모듈 필요</p>
</li>
<li><p>기계 독해 시스템의 속도 및 비용</p>
</li>
<li><p>bert as service + bert - base 이용</p>
</li>
<li><p>질의 분석기</p>
<ul>
<li>입력 쿼리의 특성분석</li>

</ul>
</li>
<li><p>검색 질의 생성기</p>
<ul>
<li><p>추출된 키워드로부터 검색 엔진에 질의할 검색 쿼리 리스트 생성</p>
</li>
<li><p>동사-명사 변환기</p>
<ul>
<li>한영/영한 사전 사용을 사용해서 </li>

</ul>
</li>

</ul>
</li>
<li><p>웹 검색 및 검색 결과 정제기</p>
<ul>
<li>사용자 질의 1회당 평균 검색 쿼리 4.6개/ 평균 반환 문서 371개</li>

</ul>
</li>
<li><p>기계 독해 기반 후보 정답 추출</p>
<ul>
<li><p>임베딩 인코더 레이어</p>
<ul>
<li>LSTM, 트랜스포머, cnn + 트랜스포머</li>

</ul>
</li>
<li><p>추가 최적화를 위해 c++ 로 inference 모듈 새로 구현</p>
</li>
<li><p>여러 layer를 동시에 연산</p>
</li>

</ul>
</li>
<li><p>기계 독해 성능</p>
<ul>
<li><p>영어 스쿼드1.1 데이터셋 사용 </p>
<ul>
<li>F1 80.3% </li>

</ul>
</li>

</ul>
</li>
<li><p>최종 정답 추출기</p>
</li>

</ul>
<ul>
<li><p>버트모델을 사용하게 되면 실시간으로 작업이 불가해서 사용하지않고 qaNet과 다른 모듈을 사용해서 실시간이 가능하도록 구현</p>
</li>
<li><p>사람평가 결과 82.2 생각보다 낮은데? </p>
</li>
<li><p>쿼리갯수를 줄이거나 MRC입력값을 낮추면 되지않을까?</p>
<ul>
<li>낮추면 바로 성능이 낮아진다. MRC 입력값을 낮추고 최대한 답변을 포함한 단락을 집어넣는게 확률을 높이는</li>

</ul>
</li>
<li><p>버트 경량화가 가능하면 성능과 시간의 문제 해결하는데 도움되지않을까?</p>
</li>

</ul>
<p>&nbsp;</p>
<h3> Attentive Aggregation (주의적 종합) 기반 크로스모달 임베딩/ 차다은</h3>
<ul>
<li><p>크로스모달 임베딩 기반 검색</p>
<ul>
<li>멀티미디어 데이터 처리를 위해 다양한 모달로부터 공통의 의미적 정보 추출 필요</li>
<li>사진 검색.</li>
<li>메타데이터기반 사진 검색 방법은 사진의 다양한 정보 반영에 한계</li>

</ul>
</li>
<li><p>한국어 정치 기사 사진/캡션 데이터로 제안 모델의 사진 검색 성능평가</p>
</li>
<li><p>주의적 종합</p>
<ul>
<li>여러 특징 벡터에 주의 메커니즘을 적용하여 하나의 종합 특징 벡터생성</li>

</ul>
</li>
<li><p>제안 모델</p>
<ul>
<li>Triplet semi hard loss</li>
<li>질의 임베딩과 사진 임베딩을 공통의 벡터 공간에 매핑</li>

</ul>
</li>
<li><p>평가 모델</p>
</li>
<li><p>성능 평가지표</p>
</li>
<li><p>실험결과</p>
</li>

</ul>
<p>&nbsp;</p>
<h3>BERT 레이어에 따른 동형이의어 의미 표현 비교</h3>
<ul>
<li>동형이의어 : 형태가 같으면서 동시에 의미가 다른 말 (임금)</li>
<li>버트 문맥을 고려한 단어 표현이 가능 &lt;- 이부분을 활용하려면 데이터셋 생성시 실제문장을 사용해야한다</li>
<li>ETRI에서 제공한 한국어 버트 언어모델 사용</li>
<li>purity 와 normalized information 정보사용</li>
<li>동형이의어와 동의어를 주제로 선택한 이유가 있을까?</li>
<li>Layer 에서 코사인 디스턴스가 증가하고 감소하는 것의 의미가 뭔지??</li>
<li>실험의결과만 나와있는데 이것의 해석은? </li>

</ul>
<p>&nbsp;</p>
<h3>자연어 이해 모델의 성능 향상을 위한 교차 게이트 메커니즘 방법</h3>
<ul>
<li>NLU : 대화모델의 맨 앞단 이라서 성능에 중요한 영향을 미친다</li>
<li>intent와 slot 사이에는 , 게이트 메커니즘을 사용해서 intent와 slot을 어디까지 반영할지에 대한 실험</li>
<li>클로바 한국어 데이터셋은 skew 되어있다. 늘 사용하는 발화만 날씨, 음악</li>
<li>크로스 게이티드 모델 특징은?</li>
<li>인텐트는 많지만 12개로 줄여서 작업.</li>

</ul>
<p>&nbsp;</p>
<h3>딥러닝과 Maximal Marginal Relevance를 이용한 2단계</h3>
<ul>
<li><p>추출요약
원본 문서에서 주요한 의미를 담고 있는 문장 몇 개를 추출하는 요약방법</p>
</li>
<li><p>생성요약</p>
<p>원본 문서의 내용을 이해하고 요약문을 생성하는 요약방법</p>
<p>seq2seq 모델을 통해서만 하면 문장의 길이가 길어지면 장거리 종속성 문제발생. Attn </p>
</li>
<li><p>mmr </p>
<p>문서 주제와 관련성이 높은 문장을 선택하면서 이전에 선택된 문장들에 대한 유사도가 낮은 문장을 선택하여 문장들 간의 중복 문제를 해결할 수 있는 방법</p>
</li>
<li><p>문장추출</p>
<ul>
<li>레이블 : 주요한문장이면 1로</li>
<li>인코더 : 평균,rnn,cnn 인코더</li>
<li>추출모델 : </li>

</ul>
</li>

</ul>
<p>&nbsp;</p>
<h3>복사-메커니즘과 추론 단계의 페널티를 이용한 Copy-Transformer 기반 문서 생성 요약</h3>
<ul>
<li><p>주요문제들</p>
<ul>
<li>사전에 없는 단어 잘못된 생성</li>
<li>디코더 단어 반복 &lt;- seq2seq 모델의 단점</li>

</ul>
</li>
<li><p>pointer generator</p>
<ul>
<li>복사메커니즘 + 커버리지 메커니즘</li>

</ul>
</li>
<li><p>학습 데이터</p>
<ul>
<li><p>네버 지식 in 질문데이터와 네이버 뉴스 요약봇의 뉴스 기사 데이터를 이용</p>
<ul>
<li>제목을 요약문으로 활용</li>
<li>학습 데이터 정제 - 연관성이 없는 데이터를 제거</li>
<li>제목이 본문의 첫 문장인 데이터 비율 조정</li>

</ul>
</li>

</ul>
</li>
<li><p>future</p>
<ul>
<li><p>rouge 점수 외의 정밀한 평가 방법 필요</p>
</li>
<li><p>pre trained lm 기반 생성 요약</p>
<ul>
<li>부족한 학습데이터 극복, 인코더 성능 향상</li>

</ul>
</li>

</ul>
</li>

</ul>
<p>&nbsp;</p>
<h3>BERT을 이용한 한국어 문장의 스타일 변화</h3>
<ul>
<li><p>seqGAN : 언어는 discrete space라 이미지에서의 gan의 생성 방법론을 그대로 적용하면 잘되지않음</p>
</li>
<li><p>언어를 무작위로 생성하는 것이 아니라 조건을 준다.</p>
<ul>
<li>데이터세트는 non-parallel 인 상황이 최근 트렌드</li>
<li>속성은 대표적으로 긍부정대한 연구</li>
<li>content는 속성에 상관없이 일정하게 유지</li>

</ul>
</li>
<li><p>bert 를 생성모델에 적용해보고싶었다</p>
<ul>
<li>문맥적 의미를 인코딩 하는데 효율적</li>
<li>콘텐츠를 보존하기 위해 backtranslation을 사용해서 </li>

</ul>
</li>
<li><p>현재 텍스트 스타일 트랜스퍼 연구가 활발히 진행중</p>
<ul>
<li>여러 가지 속성을 한꺼번에 변화</li>
<li>데이터가 적은 상황을 해결</li>
<li>반어법에 대한 연구도 필요</li>
<li>evaluation의 연구 또한 활발히 진행</li>
<li>이미지에서의 평가측정방법은 어떻게 되나?</li>
<li>현업에서는 챗봇에서 사용하는데 </li>

</ul>
</li>

</ul>
<p>&nbsp;</p>
<h3>Delete-Generate: 단어 n-gram의 삭제 및 생성에 기반한 한국어 스타일 변환</h3>
<ul>
<li><p>한국어 스타일 변환</p>
</li>
<li><p>세가지 작업을 통해 문장의 스타일을 변환</p>
<ul>
<li>삭제</li>
<li>검색</li>
<li>생성</li>

</ul>
</li>

</ul>
<ul>
<li><p>본 모델에서는 다음 3가지</p>
<ul>
<li>삭제</li>
<li>복원</li>
<li>변환</li>

</ul>
</li>
<li><p>단어 n-gram 삭제</p>
<ul>
<li>C(g,dv) : n-gram 을 삭제한 후 감성분석기가 원래 스타일이 아닐것이라고 예측한 확률</li>

</ul>
</li>
<li><p>문장 복원,변환</p>
<ul>
<li>삭제된 문장을 각각 원래 문장의 스타일별로 개별적인 seq2seq 모델을 통해 복원하도록 모델을 학습</li>

</ul>
</li>
<li><p>nsmc 데이터 를 통해 모델학습, 실험</p>
</li>
<li><p>실험결과</p>
<ul>
<li><p>감성분석기 출력은 세가지 방법으로 평가</p>
<ul>
<li>변환점수 : </li>
<li>평균변화값:</li>
<li>정확도 :</li>

</ul>
</li>

</ul>
<ul>
<li>형태소 단위로 </li>

</ul>
</li>

</ul>
<p>&nbsp;</p>
<h3>GAN에서 그래프 탐색을 이용한 유창한 문장 생성</h3>
<p>gan 모델 구조에서 유창한 문자 ㅇ생성하는 방법 제안</p>
<p>단어 그래프를 이용하여 gan 학습 도움</p>
<p>&nbsp;</p>
<ul>
<li><p>gan의 문제점</p>
<ul>
<li>모드붕괴</li>
<li>불안정적 학습</li>
<li>이산 데이터 손실 함수 -&gt; 강화학습, 정책 그라디언트</li>

</ul>
</li>
<li><p>기존연구</p>
<ul>
<li>문장생성</li>
<li>외부지식(정보) 활용</li>

</ul>
</li>
<li><p>단어그래프 탐색</p>
<ul>
<li><p>목표 : null까지 최고의 관게 값을 가지는 경로 탐색</p>
</li>
<li><p>감쇠인자 적용 0.85</p>
<ul>
<li>현재 노드에서 관계 중 가장 높은 값을 선택할 비율, 다양한 문장 생성을 위해 사용</li>

</ul>
</li>

</ul>
</li>
<li><p>데이터 및 학습, 평가</p>
<ul>
<li>세종말뭉치 10,000문장</li>

</ul>
</li>
<li><p>몬테카를로 탐색을 그래프 탐색으로 변경해서 진행</p>
</li>
<li><p>결론</p>
<ul>
<li>안정적이고 다양한 문장 생성 모델연구</li>
<li>텍스트에 맞는 손실함수 연구</li>

</ul>
</li>
<li><p>그래프탐색이 bigram하고의 차이는?</p>
</li>

</ul>
