---
layout: post
title: 나의 머신러닝 답사기3
category: Machine Learning
tags: [voyage]
---

답사기2가 18년 9월에 작성되었으니 1년이라는 시간이 훌쩍 지났다. 나는 그동안 무얼 공부했고 또 어떤 모습으로 변화되었을까 2019년의 마지막에서 간단히 내용을 정리해보려 한다
<br><br>
### [모두의 연구소 Deep Learning College](http://dlc.modulabs.co.kr/)
<br>
Deep Learning College (DLC) 2기 자연어처리 Track에 참여했다. 현재는 AI College 라는 이름으로 바뀌었지만 1년여 과정동안 기초강의 3개월, 팀프로젝트 4개월, 개인프로젝트 4개월로 이어졌다.<br>
자연어처리 기초강의에서는 SKT 연구원 분들이 직접 방문해서 gluon과 네이버 영화리뷰 데이터셋을 이용한 sentiment classification 같은 내용까지 설명을 들을 수 있었다<br>
팀프로젝트 주제는 Question Answer Generation 을 정해서 연구를 진행했다. 질문생성만 하는 모델과 답변만 생성하는 모델들은 찾을 수 있었지만 이 둘을 동시에 진행하는 모델을 찾기 어려웠고 DAANet: Dual Ask-Answer Network for Machine Reading Comprehension 이라는 논문과 코드를 찾아 수행해보았으나 논문과는 달리 잘 수행이 되지 않아 큰 벽에 부딪혔다. 쉽지 않은 연구주제를 설정했음을 알게되었고 연구를 진행할때 데이터셋의 중요성을 실감하게 되었다. 연구를 진행하는 동안에 다행히도 KorQuAD 데이터셋이 나왔지만 질문-답변 동시생성 모델에 대한 가시적인 성과는 얻지 못했다.<br>
DLC과정중 Flipped Learning 방식의 과목을 1개 수강할 수 있게 되는데 마지막 과제인 개인논문을 잘 작성하기 위한 준비로 좋은 논문들을 읽고 싶어 Slow Paper 라는 딥러닝 논문읽기 과목을 수강하게 되었다. 혼자서는 읽기 어려운 논문을 여러 사람이 모여서 3시간동안 읽게되니 그래도 끝까지 읽을 수 있었고 읽은 논문들을 하나씩 블로그 글로 정리했다. 8편의 논문이었지만 기초적인 개념들을 정리하고 다양한 분야를 접할 수 있는 좋은 기회였다.<br> 
<br><br><br>
1주차 (1/12)<br>
[Mobilenetv2: 거꾸로 된 잔차와 선형 병목](https://medium.com/@sunwoopark/slow-paper-mobilenetv2-inverted-residuals-and-linear-bottlenecks-6eacaa696b54?source=friends_link&sk=21cf2623994618735bfc94bdf13034c0&fbclid=IwAR1uV5iMRzHd-Lh1CrCcnG7-uYd47QSaHAv3rCEAYS1DZ6iRrzRuwu-9UeM)

2주차 (1/19)<br>
[라디오 신호를 이용한 벽의 포즈 추정](https://medium.com/@sunwoopark/slow-paper-through-wall-human-pose-estimation-using-radio-signals-47b76a76ec59?source=friends_link&sk=dcd82f35919a9315a99b3799e6bc93b2&fbclid=IwAR0xUqU6676ImMHydRrf9zEvSTqyBR-0SRfShgXjMqUlq5tE7eQSVLigJq0)

3주차 (1/26)<br>
[밤: 병목 주목 모듈](https://medium.com/@sunwoopark/slow-paper-bam-bottleneck-attention-module-abbf680a869?source=friends_link&sk=66bd689843e28ed0c3b6b2b3a9783441&fbclid=IwAR3lRgNDKV4tS9bvT9gowwKAUJZNxdl1C4Olvic2O5QuKavnTIyEuMZ-2EY)

4주차 (2/9)<br>
[강화 학습으로 신경 건축 검색](https://medium.com/@sunwoopark/slow-paper-neural-architecture-search-with-reinforcement-learning-6de601560522?source=friends_link&sk=148ff3d2b667cf753ce01118ac74e95a&fbclid=IwAR2KQvBx-OUjJbHhqI7HmYRN1EoBVAXSWlYCIKWyhSGMOgWkHJaRU5rQyvo)

5주차 (2/16)<br>
[글로우: invertible 1 x1 convolutions와 함께 생성 흐름](https://medium.com/@sunwoopark/slow-paper-glow-generative-flow-with-invertible-1x1-convolutions-837710116939?source=friends_link&sk=285d1ae8885cc78bfb431630974c562f&fbclid=IwAR36cppOT36VDyPeLkp0g1V04gHdvuxmVRPWqyiZwW_CePY3XrhgBQq3tAs)

6주차 (2/23)<br>
[Timbretron: a wavenet (cyclegan (cqt (오디오))) 뮤지컬 음색 전송을 위한 파이프라인](https://medium.com/@sunwoopark/slow-paper-timbretron-a-wavenet-cyclegan-cqt-audio-pipeline-for-musical-timbre-transfer-7b41f90ab62c?source=friends_link&sk=a62a878834a1a7b50471e49a2b655d72&fbclid=IwAR0puM65gkNOs8dqLA0w0VMTACmuJ06j1qBSvjI8zBV1sDoByFkHqPFroGc)

7주차 (3/9)<br>
[깊은 조건부 생성 모델을 이용한 구조적 출력 표현 학습](https://medium.com/@sunwoopark/slow-paper-learning-structured-output-representation-using-deep-conditional-generative-models-692b8dd69cf6?source=friends_link&sk=eac89c7de7beb958b045cdfce9a79afa&fbclid=IwAR2RslBeUpj2SA8EbCah7NeaKpoLgyyoybBozZgzlVUrjK-Btkx3IFEC6_0)

8주차 (3/16)<br>
[스타일-attentional 네트워크로 임의 스타일 전송](https://medium.com/@sunwoopark/slow-paper-arbitrary-style-transfer-with-style-attentional-networks-8e0c3206168e?source=friends_link&sk=fa81992704dc7414b3a0142d8271afd0&fbclid=IwAR38horX6UnN-UFyi-IA4E2Z3nywszsdGrY7JlNjsxVByufR2r-v1ePPD8M)
<br>

마지막 개인프로젝트는 논문작성이었고 주제를 정하기가 쉽지않았다. 결국에는 한국어문장에 대한 딥러닝 OCR 모델에 대한 내용으로 정하고 진행하였다. OCR 프로젝트는 네이버에서 진행된 프로젝트를 많이 참고했고 한국어 문장 데이터셋은 따로 없어서 폰트와 많이 사용되는 어휘사전을 이용해서 직접 생성해서 진행했다. 해당 프로젝트 상세내용은 다른 포스트로 내용을 정리하고자 한다. 처음 작성한 논문이 HCLT 2019 에 채택되어서 포스터발표를 하게되는 영광을 누리게되었다.
[ocr_kor](https://github.com/parksunwoo/ocr_kor)
<br><br>


### MIT_데이터 사이언스 기초
[강의링크](https://www.edwith.org/datascience/lecture/33888/)<br>
[강의정리 Git](https://github.com/parksunwoo/TIL/blob/master/data-science/README.md)<br>
<br>
15 chapter의 데이터 사이언스 기초강의를 듣고 Git에 정리했다. 예전 Data Science Bootcamp 내용을 복습할겸 전체내용을 다시 정리하기에 좋았다. 
<br>

### 하버드_확률론 기초: Statistics 110
[강의링크](https://www.edwith.org/harvardprobability/joinLectures/17924)
[강의정리 Git](https://github.com/parksunwoo/TIL/blob/master/statistics/README.md)<br>

아직도(?) 진행중이긴 하지만 확률은 강의를 듣고 정리해두면 두고두고 사용할수 있을 것이라 남은 내용들도 다시 듣고 정리해보려 한다.
[edwith](https://www.edwith.org/)에는 좋은 강의들을 엄선해서 다시 번역까지 해놓은 곳이라 필요한 과목들만 골라서 보기에 추천하는 사이트이다.

<br><br>
올해에도 여러 컨퍼런스에 참여했고 보고 들은것을 기록으로 남겼다.<br>
[파이콘 2019](https://parksunwoo.github.io/pyconkr2019/)<br>
[한글및한국어정보처리학술대회 2019 1일차](https://parksunwoo.github.io/HCLT2019_day1/)<br>
[한글및한국어정보처리학술대회 2019 2일차](https://parksunwoo.github.io/HCLT2019_day2/)<br>
[모두콘 2019](https://parksunwoo.github.io/moducon2019/)

<br><br>
DLC 과정을 시작할때에는 막연히 1년과정이 끝나면 좋은 기회가 생기지않을까 하는 기대감이 있었다.<br> 
데이터 사이언티스트를 꿈꾸며 길을 걷고 있었지만 파이썬이라는 언어의 매력에 빠지게 되었다.<br> 
그리고 모두의연구소 라는 곳에서 공부하면서 그곳에 있는 사람들과 그곳이 나아가는 방향에 깊은 공감을 하게되었다. 내년부터는 모두의연구소의 Backend Engineer 로 더 많은 사람들이 AI와 ML/DL를 배울 수 있는 연구생태계를 만들어보려 한다.<br>
지금까지 하고 있던 웹개발을 Django라는 새로운 언어로 하게 되어 현재는 강의를 들으며  django를 공부중이다. 그럼 나의 머신러닝 답사기는 다시 웹개발로 돌아오게되어 끝이 난건가? ^^
<br><br>
나는 이제 Ai Engineer라는 새로운 목표를 세우고 어떤 분야 어떤 주제를 파볼지 정해보려 한다.<br> 
놀이터에서 일하게 되었으니 다양한 분야를 좀더 가까이에서 접해보고 연구원분들과도 되도록 많은 이야기를 나눠보고 싶다.<br> 
그곳에서의 새로운 경험은 나를 또 다른 길로 이어지게 할것이고 2020년은 지금까지보다 더 기대되는 한해가 될것같다.<br><br><br>



















 



